{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Cheatsheet\n",
    "### Python Lists, Tuples, Sets, and Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of 'ex' in list is: 8\n",
      "Reverse sorted copy of list: [20, 16, 12, 8, 5.5, 4, 0]\n",
      "Is 16 in x? True\n",
      "Value for 'MONDAY' key: some_val\n",
      "1 TUESDAY\n",
      "2 WEDNESDAY\n",
      "3 THURSDAY\n",
      "4 FRIDAY\n",
      "5 SATURDAY\n",
      "6 SUNDAY\n"
     ]
    }
   ],
   "source": [
    "## List\n",
    "x = list(range(0,21,4))\n",
    "x.insert(2,'in1') # Insert an element at second position\n",
    "x.append('a1') # Append an element to the end\n",
    "x.extend(['ex','ex']) # Extend the list by adding all the elements of another list to the end\n",
    "print('Index of \\'ex\\' in list is:', x.index('ex')) # Return the index of the first occurence of an element (also works on tuples)\n",
    "x.pop() # Return the last element of a list and remove it from the list (doesn't work for tuples and will pop a random element if used on sets)\n",
    "x.remove('a1') # Remove first occurence of element 'a1' from list\n",
    "del x[-1] # Delete last element from list\n",
    "x.reverse() #reverse order of the list\n",
    "y = x.copy() # Create a copy of the list\n",
    "x = x[0:7] # Slice a list\n",
    "x[4] = 5.5  # Reassign a value to a list element (can't use it to assign a new value to be added to the list, must use append there)\n",
    "x.sort() # Sort list if sortable (i.e. if all elements can be compared)\n",
    "minx,maxx,sumx = (min(x),max(x),sum(x))  # Assign multiple values using tuples; calcualte min, max, sum on a list (also works on tuples and sets)\n",
    "print('Reverse sorted copy of list:', sorted(x,reverse=True))  # Return a sorted copy of x but don't change x itself\n",
    "print('Is 16 in x?', 16 in x)  # Check if something is in a list, set or a tuple\n",
    "\n",
    "\n",
    "## Sets\n",
    "x = set(range(0,21,4))\n",
    "y = set(range(12,25,2))\n",
    "x.difference(y) # Equal to 'x-y' and gives all elements only in x (and not in y)\n",
    "x.union(y) # Equal to 'x-y' and gives all elements only in x (and not in y)\n",
    "x.intersection(y) # Equal to 'x-y' and gives all elements only in x (and not in y)\n",
    "x.symmetric_difference(y) # Returns elements in union minus intersection (equivalent to y.symmetric_differenc(x) )\n",
    "x.add('a') # Add 'a' to the set x\n",
    "x.update(y,[9,7]) # Can take more than one sets, lists or other things as or\n",
    "x.remove('a') # Discard element. Throw error if element does not exist\n",
    "x.discard('a') # Discard element. Do not throw error if element does not exist\n",
    "y.issubset(x) # Is y a subset of x. Return True or False\n",
    "y.issuperset(x) # Is y a superset of x. Return True or False\n",
    "\n",
    "## Dictionary\n",
    "x = dict(zip(('MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY'),range(7)))\n",
    "x.pop('MONDAY','some_value_to_return_when_key_missing (optional)')  # Remove a key (along with associated value) from the dictionary. Absence of key in dict and that of optional argument with throw error\n",
    "print('Value for \\'MONDAY\\' key:', x.get('MONDAY','some_val'))  # Return 'some_val' with \"get\" method instead of 0 since MONDAY:0 key:val pair was removed.\n",
    "x = {value:key for key, value in x.items()} # Dictionary comprehension\n",
    "for key,val in x.items():  # Iterate over a dictionary key,value pairs\n",
    "    print(key,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings and Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29384723 KB is 29.4 GB.\n",
      "29384723 Kb Is 29.4 Gb.\n",
      "12\n",
      "['29384723', 'KB', 'is-29.4-GB.']\n"
     ]
    }
   ],
   "source": [
    "SUFFIXES = ['KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB']\n",
    "sizekb = 29384723\n",
    "sizemb = sizekb/1000000\n",
    "s1 = '{1} {0[0]} is {2:.1f} {0[2]}.'.format(SUFFIXES, sizekb, sizemb)  # String formatting. Note you can call elements of a list by passing a list here. \n",
    "                                                                       # \":\" marks begining of format specifier. The \".1\" makes sure you show 1 decimal places and \n",
    "                                                                       # \"f\" specifies it to show as fixed-point number (as opposed to e for exponential)\n",
    "print(s1)\n",
    "print(s1.title()) # Return a new string with title case, i.e. first letter caps. Same for \".lower()\" and \".upper()\" works.\n",
    "print(s1.find('is')) # Find and return the index of the begining of the first letter of a given substring in the sring.\n",
    "s1.count('is') # Return count of a substring.\n",
    "s1 = s1.replace(' ','-') # Return a new string by replacing all occurences of space by '-'\n",
    "print(s1.split('-',2)) # Split using first two occurences of the specified demiliter '-' giving list of len 3. \".splitlines()\" similarly splits into lines.\n",
    "\n",
    "\n",
    "## Regex\n",
    "import re\n",
    "p1 = '^M{0,3}(XC|XL|L?X{0,3})$'\n",
    "re.search(p1, 'MMLXXX')  # Search for pattern in a string and return the method\n",
    "pattern = '''\n",
    "    ^                   # match beginning of string\n",
    "    M{0,3}              # match 0 to 3 Ms\n",
    "    (XC|XL|L?X{0,3})    # match XC OR XL OR 0 to 1 L followed by 0 to 3 Xs\n",
    "    $                   # match end of string\n",
    "    ''' # This verbose pattern is same as the pattern p1 above\n",
    "re.search(pattern, 'MMLXXX', re.VERBOSE) # To searcha  verbose pattern an extra argument must be passed - unless it is compiled with the right flags below\n",
    "\n",
    "# Another pattern to help\n",
    "phonePattern = re.compile(r'''\n",
    "                # don't match beginning of string, number can start anywhere\n",
    "    (\\d{3})     # area code is 3 digits (e.g. '800')\n",
    "    \\D*         # optional separator is any number of non-digits\n",
    "    (\\d{3})     # trunk is 3 digits (e.g. '555')\n",
    "    \\D*         # optional separator\n",
    "    (\\d{4})     # rest of number is 4 digits (e.g. '1212')\n",
    "    \\D*         # optional separator\n",
    "    (\\d*)       # extension is optional and can be any number of digits\n",
    "    $           # end of string\n",
    "    ''', re.VERBOSE)\n",
    "\n",
    "# Complete comments on: re.search, match, fullmatch, split, findall, finditer, sub, subn, escape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generators, Classes, and Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n"
     ]
    }
   ],
   "source": [
    "# Define a fibonacci generator\n",
    "def fib(max): \n",
    "    '''Fibonacci generator up to a max value.'''\n",
    "    a, b = 0, 1\n",
    "    while a < max:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        \n",
    "fib50 = fib(50)  # Construct the generator that will generate values up to 1000 when used\n",
    "print([i for i in fib50])  # Use the generator\n",
    "    \n",
    "    \n",
    "gen1 = (i**2 for i in range(50) if i%2==1) # Generators can be created same as using list comprehensions. Here we have one that generates sqares of all odd numbers below 50\n",
    "    \n",
    "'''A class is the blueprint of an object that can have variables and methods defined (data attributes and method attributes of the class) by the user. \n",
    "Variables can be instance variables or class variables. Data attributes will usually overwrite method attributes so naming conventions can be valuable.\n",
    "An iterator is an object with a __next__ method. Below is a custom class that implements the Fib iterator from scratch.\n",
    "'''\n",
    "class Fib:\n",
    "    classvar1 = 0  # Example of a calss variable (not used in this class, simply here to illustrate). self.classvar1 will get you this variable.\n",
    "    \n",
    "    def __init__(self, max): # An init method is called when a class is instatiated. You should pass these arguments to the class when creating the instance.\n",
    "        self.max = max   # Example of an instance variable\n",
    "\n",
    "    def __iter__(self):  # This method makes this class an iterable. This method returns an iterator - something that has __next__ method, in this case self.\n",
    "        self.a = 0\n",
    "        self.b = 1\n",
    "        return self\n",
    "\n",
    "    def __next__(self):  # An iterator is something that implements this __next__ method. In this case self is both the iterable and iterator but doesn't have to be.\n",
    "        fib = self.a\n",
    "        if fib > self.max:\n",
    "            raise StopIteration\n",
    "        self.a, self.b = self.b, self.a + self.b\n",
    "        return fib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Time and Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1776-07-04 ;   2018-08-13\n",
      "-88428 days, 0:00:00\n",
      "0\n",
      "Mon, August 13, 2018 OR 08-13-18\n",
      "2018-08-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.date.today()\n",
    "print(datetime.date(1776,7,4),\";  \",today)  # Define a date object. Similarly can define a datetime or a time object\n",
    "print(datetime.date(1776,7,4) - datetime.date.today())  # Define a date object. Similarly can define a datetime or a time object\n",
    "datetime.timedelta(days=1, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)  # Define timedelta. This is the object you get when you take the difference of two datetime objects\n",
    "print(datetime.date.weekday(datetime.date.today())) # Print the weekday integer with Monday being 0\n",
    "today_str = today.strftime('%a, %B %d, %Y OR %m-%d-%y')  # Return the date as a string in any format you like\n",
    "print(today_str)\n",
    "print(datetime.datetime.strptime(today_str[:20], '%a, %B %d, %Y'))  # Take a string and read date object from it based on specified format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map, Filter and Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 16, 81]\n",
      "[-5, -4, -3, -2, -1]\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x**2, (1,4,9))))  # Apply a function to each element and return a list. Map will also work on list of functions etc, as long as the operations are valid, any objects are fine\n",
    "number_list = range(-5, 5)\n",
    "print(list(filter(lambda x: x < 0, range(-5, 5)))) # Filter based on an arbitrary function\n",
    "from functools import reduce\n",
    "print(reduce((lambda x, y: x * y**2), [1, 2, 3, 4]))  # A very interesting function that can calculate results on a rolling basis and reduce. Here, the result comes from ((1*(2**2)) * (3**2)) * (4**2). Basically output of last calculation is the \"x\" value for the next calculation and the \"y\" value is the next value in the iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "#### Getting Information and Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Frame:\n",
      "            A          B    C         D      E    F\n",
      "funindex                                          \n",
      "i0         9 2013-01-02  1.0  5.269844   test  foo\n",
      "i1        19 2013-01-02  1.0  7.780302  train  bar\n",
      "i2        29 2013-01-02  1.0  9.499163   test  foo\n",
      "i3        39 2013-01-02  1.0  6.248753  train  baz\n",
      "i4        49 2013-01-02  1.0  5.977056   test  foo\n",
      "i5        59 2013-01-02  1.0  2.751343  train  bar\n",
      "i6        69 2013-01-02  1.0  4.701653   test  foo\n",
      "i7        79 2013-01-02  1.0  7.034834  train  baz\n",
      "\n",
      "Shape is:\n",
      " (8, 6)\n",
      "\n",
      "\n",
      "Information is:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8 entries, i0 to i7\n",
      "Data columns (total 6 columns):\n",
      "A    8 non-null int64\n",
      "B    8 non-null datetime64[ns]\n",
      "C    8 non-null float32\n",
      "D    8 non-null float64\n",
      "E    8 non-null category\n",
      "F    8 non-null object\n",
      "dtypes: category(1), datetime64[ns](1), float32(1), float64(1), int64(1), object(1)\n",
      "memory usage: 456.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "df1 = pd.DataFrame({ 'A' : range(9,80,10), \n",
    "                    'B' : pd.Timestamp('20130102'), \n",
    "                    'C' : pd.Series(1,index=list(range(8)),dtype='float32'), \n",
    "                    'D' : np.random.rand(8)*10, \n",
    "                    'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\",\"test\",\"train\",\"test\",\"train\"]), \n",
    "                    'F' : ['foo','bar','foo','baz','foo','bar','foo','baz'] })\n",
    "\n",
    "df1.index = ('i'+str(i) for i in range(8)) # Set index to something more interesting for highlighting slicing better\n",
    "df1.index.name = 'funindex'  # You can name the index\n",
    "print('Original Frame:\\n',df1)\n",
    "print('\\nShape is:\\n', df1.shape)\n",
    "print('\\n\\nInformation is:\\n')\n",
    "print(df1.info())\n",
    "\n",
    "# Reading files\n",
    "chipo = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv', sep='\\t', header = 0, skiprows = [1,4,6,8]) # Header tells you which row is header if any. Use name to provide custom header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Stats etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series Counts:\n",
      " train    4\n",
      "test     4\n",
      "Name: E, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A    44.000000\n",
       "C     1.000000\n",
       "D     6.157868\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nSeries Counts:\\n', df1['E'].value_counts()) # For a pandas series, present counts for each value/category\n",
    "df1.mean(axis=0) # Same works for sum, max, min etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sliced Frame:\n",
      "            A          B\n",
      "funindex               \n",
      "i0         9 2013-01-02\n",
      "i1        19 2013-01-02\n",
      "\n",
      "Filtered Frame:\n",
      "            A          B    C         D     E    F\n",
      "funindex                                         \n",
      "i0         9 2013-01-02  1.0  5.269844  test  foo\n",
      "i2        29 2013-01-02  1.0  9.499163  test  foo\n",
      "i4        49 2013-01-02  1.0  5.977056  test  foo\n",
      "i6        69 2013-01-02  1.0  4.701653  test  foo\n",
      "\n",
      "Index based slicing:\n",
      "            A          B    C\n",
      "funindex                    \n",
      "i0         9 2013-01-02  1.0\n",
      "i4        49 2013-01-02  1.0\n",
      "\n",
      "Location based slicing:\n",
      "                   B    C\n",
      "funindex                \n",
      "i0       2013-01-02  1.0\n",
      "i4       2013-01-02  1.0\n",
      "\n",
      "Selecting an setting element using at:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "print('\\nSliced Frame:\\n', df1[['A','B']][:2])  # Slice on columns and rows (order is unimportant here). For columns you have to specify a list and for rows a range with :\n",
    "print('\\nFiltered Frame:\\n', df1[df1['E']=='test'])  # Filter for column E being 'test'\n",
    "print('\\nIndex based slicing:\\n', df1.loc[['i0','i4'],'A':'C']) # You can either give range here or a list of indices. Full range is included here\n",
    "print('\\nLocation based slicing:\\n', df1.iloc[[0,4],1:3]) # You can either give range here or a list of indices. Full range is included here\n",
    "print('\\nSelecting an setting element using at:\\n', df1.at['i1','C']) # You can pull any value from the frame and set it to whatever you like. Same for the .iat that works like .iloc but for one val only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting, Casting etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A          B    C         D      E    F\n",
      "funindex                                          \n",
      "i1        19 2013-01-02  1.0  7.780302  train  bar\n",
      "i7        79 2013-01-02  1.0  7.034834  train  baz\n",
      "i3        39 2013-01-02  1.0  6.248753  train  baz\n",
      "i5        59 2013-01-02  1.0  2.751343  train  bar\n",
      "i2        29 2013-01-02  1.0  9.499163   test  foo\n",
      "i4        49 2013-01-02  1.0  5.977056   test  foo\n",
      "i0         9 2013-01-02  1.0  5.269844   test  foo\n",
      "i6        69 2013-01-02  1.0  4.701653   test  foo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "funindex\n",
       "i0    1\n",
       "i1    1\n",
       "i2    1\n",
       "i3    1\n",
       "i4    1\n",
       "i5    1\n",
       "i6    1\n",
       "i7    1\n",
       "Name: C, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.sort_values(by=['E','D'], ascending= False, inplace = False, na_position = 'last')) # First sort on D then sort on E. So E is really sorted, and within each value of E, D is sorted.\n",
    "df1['C'].astype(int) # Cast the type of a pandas column to another type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frame Groups:\n",
      " {1.0: Index(['i5', 'i6'], dtype='object', name='funindex'), 2.0: Index(['i0', 'i3', 'i4', 'i7'], dtype='object', name='funindex'), 3.0: Index(['i1', 'i2'], dtype='object', name='funindex')}\n",
      "\n",
      "Get group by it's name:\n",
      "            A          B    C         D      E    F\n",
      "funindex                                          \n",
      "i1        19 2013-01-02  1.0  7.780302  train  bar\n",
      "i5        59 2013-01-02  1.0  2.751343  train  bar\n",
      "         A    C          D\n",
      "E                         \n",
      "test   156  4.0  25.447715\n",
      "train  196  4.0  23.815232\n"
     ]
    }
   ],
   "source": [
    "gr = df1.groupby(list(map(lambda x: x//(10/4.), df1['D'])), axis=0) # Group based on quartiles\n",
    "print('\\nFrame Groups:\\n',gr.groups)\n",
    "print(\"\\nGet group by it's name:\\n\", df1.groupby('F').get_group('bar'))\n",
    "print(df1.groupby('E').sum())  # Quick summary statistics on groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing data in Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     2\n",
      "Z    10\n",
      "B     2\n",
      "C     2\n",
      "D     2\n",
      "E     3\n",
      "F     3\n",
      "dtype: int64\n",
      "np.nan == np.nan : False\n",
      "None == None : True\n",
      "            C         D     A                    B    F\n",
      "funindex                                               \n",
      "i0        1.0  5.269844   9.0  2013-01-02 00:00:00  foo\n",
      "i5        1.0  2.751343  59.0  2013-01-02 00:00:00  bar\n",
      "i9        2.0  2.000000   2.0                    2    2\n",
      "i2        1.0  9.499163  29.0  2013-01-02 00:00:00  foo\n",
      "i1        1.0  7.780302  19.0  2013-01-02 00:00:00  bar\n",
      "i3        1.0  6.248753  39.0  2013-01-02 00:00:00  baz\n",
      "i4        1.0  5.977056  49.0  2013-01-02 00:00:00    2\n",
      "i6        1.0  4.701653  69.0  2013-01-02 00:00:00  foo\n",
      "i7        1.0  7.034834  79.0  2013-01-02 00:00:00  baz\n",
      "E         2.0  2.000000   2.0                    2    2\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "df2 = df1.reindex(index = ['i0', 'i5', 'i9', 'i2', 'i1', 'i3', 'i4', 'i6', 'i7', 'E'], columns = ['A', 'Z', 'B', 'C', 'D', 'E', 'F'])\n",
    "df2.at['i3','E']=None\n",
    "df2.at['i4','F']=None\n",
    "print(df2.isna().sum())   # \"notna\" works the same. Get a frame of where NA is. This includes None values in \"objects\". Works on series as well.\n",
    "'''Note: You CANNOT check np.nan by equating it to np.nan even though that's what is mostly used in NA's in pandas. \n",
    "Reason being np.nan != np.nan. Hoewever, in python None = None. Only object types will hold None though'''\n",
    "print('np.nan == np.nan :', np.nan == np.nan)\n",
    "print('None == None :', None == None)\n",
    "df2['F'].fillna('baz',inplace=False) # Fill with a particular value\n",
    "df3=df2.fillna(pd.Series([909,'zcol',datetime.date(2018,1,1),1.,4.4,'test','baz'], index=df2.columns),axis=0)  # You can also fill with any seris where index matches\n",
    "df2.fillna(df2.mean(axis=0), axis=0)  # Good use case is when you can just use mean\n",
    "df2.drop(columns=['Z']).dropna(axis=0)  # Drop all rows or columns that contain an NA\n",
    "df2[['A','C','D']].interpolate(axis=0)   # Interpolate values in a linear fashion and fill NA's. This will not work if you have a column in there that is boject/text type or categorical\n",
    "print(df2[['C','D','A','B','F']].replace(np.nan,2))  # Here it works for np.nan to replace (None will fail except on object type columns). However, a replacement for categorical should be categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A    C          D\n",
      "funindex                      \n",
      "i0          81  1.0  27.771254\n",
      "i1         361  1.0  60.533104\n",
      "i2         841  1.0  90.234094\n",
      "i3        1521  1.0  39.046909\n",
      "i4        2401  1.0  35.725196\n",
      "i5        3481  1.0   7.569888\n",
      "i6        4761  1.0  22.105540\n",
      "i7        6241  1.0  49.488896\n",
      "A    352.000000\n",
      "C      8.000000\n",
      "D     49.262948\n",
      "dtype: float64\n",
      "A    [1, 2, 3]\n",
      "C    [1, 2, 3]\n",
      "D    [1, 2, 3]\n",
      "dtype: object\n",
      "            A    C    D\n",
      "funindex               \n",
      "i0        4.0  4.0  4.0\n",
      "i1        4.0  4.0  4.0\n",
      "i2        4.0  4.0  4.0\n",
      "i3        4.0  4.0  4.0\n",
      "i4        4.0  4.0  4.0\n",
      "i5        4.0  4.0  4.0\n",
      "i6        4.0  4.0  4.0\n",
      "i7        4.0  4.0  4.0\n",
      "    A  C  D\n",
      "i1  1  1  1\n",
      "i2  2  2  2\n",
      "i3  3  3  3\n",
      "funindex\n",
      "i0     8.0\n",
      "i1    18.0\n",
      "i2    28.0\n",
      "i3    38.0\n",
      "i4    48.0\n",
      "i5    58.0\n",
      "i6    68.0\n",
      "i7    78.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df1.applymap(lambda x: str(x)+'--Converted')  # Apply an elementwise function to the entire dataframe. If it is a mixed dataframe this will fail of course.\n",
    "print(df1[['A', 'C', 'D']].apply(lambda x: x**2, axis = 0, result_type = None))  # Pass entire columns or rows to the function and then depending on the output of the lambda function you might get a series or a df or something else in the end. \n",
    "print(df1[['A', 'C', 'D']].apply(lambda x: sum(x), axis = 0, result_type = None))  # Here for example lambda function returns a tuple\n",
    "print(df1[['A', 'C', 'D']].apply(lambda x: [1,2,3], axis = 0, result_type = None))  # Here for example lambda function returns a list\n",
    "print(df1[['A', 'C', 'D']].apply(lambda x: 4, axis = 0, result_type = 'broadcast'))  # Here for example lambda function returns a number, same as the (sum) above. But we broadcast to original dimensions\n",
    "print(df1[['A', 'C', 'D']].apply(lambda x: pd.Series((1,2,3), index =['i1','i2','i3'] ), axis = 0, result_type = None))  # Here for example lambda function returns a tuple\n",
    "print(df1[['A', 'C', 'D']].apply(lambda x: x['A']-x['C'], axis = 1, result_type = None))  # Taking the difference of two elements when rows are passed using axis=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concate, append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B    E   D    C\n",
      "0  A0  B0   C0  D0  NaN\n",
      "1  A1  B1   C1  D1  NaN\n",
      "2  A2  B2   C2  D2  NaN\n",
      "3  A3  B3   C3  D3  NaN\n",
      "X  X0  X1  NaN  X3   X2 \n",
      "                 A    B    E    D    C\n",
      "group_key                            \n",
      "x         0    A0   B0   C0   D0  NaN\n",
      "          1    A1   B1   C1   D1  NaN\n",
      "          2    A2   B2   C2   D2  NaN\n",
      "          3    A3   B3   C3   D3  NaN\n",
      "y         4    A4   B4  NaN   D4   C4\n",
      "          2    A5   B5  NaN   D5   C5\n",
      "          6    A6   B6  NaN   D6   C6\n",
      "          7    A7   B7  NaN   D7   C7\n",
      "z         8    A8   B8  NaN   D8   C8\n",
      "          9    A9   B9  NaN   D9   C9\n",
      "          10  A10  B10  NaN  D10  C10\n",
      "          11  A11  B11  NaN  D11  C11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpatel124\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'E': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']}, index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']}, index=[4, 2, 6, 7])\n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']}, index=[8, 9, 10, 11])\n",
    "\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']}, index=[2, 3, 6, 7])\n",
    "\n",
    "frames = [df1, df2, df3]\n",
    "r0 = df1.append([df2, df3], sort=True, ignore_index = True) # This is exactly the same as below with joint=outer and axis=0 and not providing other info when using with dfs, but different with series\n",
    "r1 = pd.concat(frames, axis=0, sort=False, join='outer', ignore_index=False, keys=['x', 'y', 'z'])  # The join = 'outer' here means all columns will be there; 'inner' would only show columns A,B,D\n",
    "r2 = pd.concat(frames, axis=0, sort=False, join_axes = [pd.Index(['A','B','C','D'])], ignore_index=False, keys=['x', 'y', 'z']) # Instead of outer or inner, you can also provide specific index\n",
    "\n",
    "s1 = pd.Series(['X0', 'X1', 'X2', 'X3'], name = 'X', index=['A', 'B', 'C', 'D'])\n",
    "r3 = pd.concat([df1, pd.Series(['X0', 'X1', 'X2', 'X3'], name = 'X')], axis=1) # Series can be concatenated to a pandas dataframe as a column with it's name as column name\n",
    "r4 = pd.concat([df1, s1], axis=0, sort=False) # Compare this behavior of concat with the following behavior of append\n",
    "r5 = df1.append(s1, sort=False)  # The same behavir of append can of-course be obtained by doing the below so r6 is same as r5\n",
    "r6 = pd.concat([df1, pd.DataFrame(s1).transpose()], axis=0, sort=False) # Compare this behavior of concat with the following behavior of append\n",
    "\n",
    "pieces = {'x': df1, 'y': df2, 'z': df3}  # Can also use dictionary to pass key-df pairs\n",
    "r7 = pd.concat(pieces, axis=0, sort=False, join='outer', ignore_index=False, keys=['x','z']) # in this case you can use the keys argument here to filter really\n",
    "r8 = pd.concat(pieces, keys=['x', 'y', 'z'], levels=[['z', 'y', 'x', 'w']], names=['group_key'], sort=False) # You can always specify levels and names for a multiindex frame\n",
    "print(r6,'\\n',r8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge, Join"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, \n",
    "                      sort=True, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'], \n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3'],\n",
    "                      'E': [1,1,2,3]})\n",
    "left.index.name = 'lidx'\n",
    "m1 = pd.merge(left, right, on=['key1', 'key2'], validate = 'one_to_many', sort=False)  # If the key names are same you can use it to do joins\n",
    "# If your index is named, the left_on and right_on arguments can contain named indices\n",
    "m2  = pd.merge(left, right, left_on=['lidx', 'key2', 'key1'], right_on=['E', 'key1', 'key2'], how='outer', indicator=True)\n",
    "m3 = pd.merge(right, right, left_index = True, right_on=['E'], how='outer') # Self Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2   A   B   C   D  E\n",
      "0   K0   K0  A0  B0  C0  D0  1\n",
      "1   K1   K0  A2  B2  C1  D1  1\n",
      "2   K1   K0  A2  B2  C2  D2  2\n"
     ]
    }
   ],
   "source": [
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
